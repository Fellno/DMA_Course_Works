{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Base分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/fellno/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import keras as kr\n",
    "\n",
    "\n",
    "# 实时更新进度条\n",
    "def print_flush(print_string):\n",
    "    print(print_string, end='\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# 获取显存动态增长的会话 \n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    return session\n",
    "\n",
    "predictor_set = [\"THUCNews\", \"TouTiao\"]\n",
    "name_of_predictor = predictor_set[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 路径导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382688"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getFilePath(rootDir):\n",
    "    filePath_list = []\n",
    "    for root, dirs, files in os.walk(rootDir):\n",
    "        filePath_list += [os.path.join(root, file) for file in files if file != \".DS_Store\"]\n",
    "    return filePath_list\n",
    "\n",
    "filePath_list = getFilePath(\"./DataSets/\" + name_of_predictor)\n",
    "len(filePath_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件内容读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filePath_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-677524578041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msample_quantity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcontent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filePath_list' is not defined"
     ]
    }
   ],
   "source": [
    "def getFile(filePath):\n",
    "    with open(filePath, 'r', encoding='utf8') as file:\n",
    "        fileContent = file.read()\n",
    "    return fileContent\n",
    "\n",
    "sequence_length = 600\n",
    "sample_quantity = len(filePath_list)\n",
    "startTime = time.time()\n",
    "content_list = []\n",
    "for i in range(sample_quantity):\n",
    "    filePath = filePath_list[i]\n",
    "    \n",
    "    # 获取文本\n",
    "    fileContent = getFile(filePath)\n",
    "    # 正则处理\n",
    "    fileContent_1 = re.sub('\\s+', ' ', fileContent)\n",
    "    # 长度截断\n",
    "    fileContent_2 = fileContent_1[:sequence_length]\n",
    "    content_list.append(fileContent_2)\n",
    "    \n",
    "    # 进度条\n",
    "    index = i + 1\n",
    "    if index % 100 == 0 or index == sample_quantity:\n",
    "        percent = index / sample_quantity * 100\n",
    "        percent_int = int(percent)\n",
    "        half_percent_int = int(percent_int / 2)\n",
    "        string_0 = \"{0} / {1} \".format(index, sample_quantity)\n",
    "        string_1 = '>' * half_percent_int + ' ' * (50 - half_percent_int)\n",
    "        string_2 = \" Percentage: {:.2f}%\".format(percent)\n",
    "        usedTime = time.time() - startTime\n",
    "        string_3 = \" Process speed: {:.2f} files/sec\".format(index / usedTime)\n",
    "        string_4 = \" Total time: {:.2f} Seconds.\".format(usedTime)\n",
    "        print_string = string_0 + string_1 + string_2 + string_3 + string_4\n",
    "        print_flush(print_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件内容序列化保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content serialization finished.\n"
     ]
    }
   ],
   "source": [
    "# 创建content_list文件夹\n",
    "dir_name = \"./\" + name_of_predictor + \"/content_list\"\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "    \n",
    "pickleFilePath = \"./\" + name_of_predictor + \"/content_list/content_list.pickle\"\n",
    "with open(pickleFilePath, 'wb') as file:\n",
    "    pickle.dump(content_list, file)\n",
    "print(\"Content serialization finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件内容加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content load finished.\n"
     ]
    }
   ],
   "source": [
    "pickleFilePath = \"./\" + name_of_predictor + \"/content_list/content_list.pickle\"\n",
    "with open(pickleFilePath, 'rb') as file:\n",
    "    content_list = pickle.load(file)\n",
    "print(\"Content load finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本标签列表获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label length: 382688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "科技    41543\n",
       "娱乐    39396\n",
       "体育    37568\n",
       "汽车    35785\n",
       "游戏    29300\n",
       "文化    28031\n",
       "金融    27085\n",
       "教育    27058\n",
       "世界    26909\n",
       "军事    24984\n",
       "旅游    21422\n",
       "农业    19322\n",
       "房产    17672\n",
       "民生     6273\n",
       "股票      340\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ！！自改 可能有问题\n",
    "def get_label_list(rootDir):\n",
    "    label_list = []\n",
    "    for filePath in filePath_list:\n",
    "        label_list.append(filePath.split('/')[3])\n",
    "    return label_list\n",
    "\n",
    "label_list = get_label_list(\"./DataSets/\" + name_of_predictor)\n",
    "print('Label length:', len(label_list)) \n",
    "pd.value_counts(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本标签列表序列化保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label list serialization finished.\n"
     ]
    }
   ],
   "source": [
    "pickleFilePath = './' + name_of_predictor + '/label_list.pickle'\n",
    "\n",
    "with open(pickleFilePath, 'wb') as file:\n",
    "    pickle.dump(label_list, file)\n",
    "print(\"Label list serialization finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本标签列表读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label list load finished.\n"
     ]
    }
   ],
   "source": [
    "with open('./' + name_of_predictor + '/label_list.pickle', 'rb') as file:\n",
    "    label_list = pickle.load(file)\n",
    "print(\"Label list load finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词汇表建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词汇表构建和存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382688/ 382688 Processed: 100.00% Time cost: 3.97秒\r"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_word_list(content_list, size):\n",
    "    startTime = time.time()\n",
    "    counter = Counter()\n",
    "    sample_quantity = len(content_list)\n",
    "    for i, content in enumerate(content_list, 1):\n",
    "        counter.update(content)\n",
    "        if i%1000==0 or i==sample_quantity:\n",
    "            string_0 = '%d/ %d' %(i, sample_quantity)\n",
    "            string_1 = ' Processed: %.2f%%' %(i/sample_quantity*100)\n",
    "            usedTime = time.time() - startTime\n",
    "            string_2 = ' Time cost: %.2f秒' %usedTime\n",
    "            print_string = string_0 + string_1 + string_2\n",
    "            print_flush(print_string)\n",
    "    word_list_1 = [k[0] for k in counter.most_common(size-1)]\n",
    "    word_list = ['PAD'] + word_list_1\n",
    "    return word_list\n",
    "\n",
    "\n",
    "vocabulary_size = 7000\n",
    "word_list = get_word_list(content_list, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words list saved.\n"
     ]
    }
   ],
   "source": [
    "with open('./' + name_of_predictor + '/word_list.pickle', 'wb') as file:\n",
    "    pickle.dump(word_list, file)\n",
    "print(\"Words list saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词汇表读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words list loaded.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./' + name_of_predictor + '/word_list.pickle', 'rb') as file:\n",
    "    word_list = pickle.load(file)\n",
    "print(\"Words list loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入X文字序列转id序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 600\n",
    "# 初始化id序列对查表\n",
    "word2id_dict = dict([(b, a) for a, b in enumerate(word_list)])\n",
    "\n",
    "# 单文章转id列表\n",
    "def get_id_list(index):\n",
    "    content = index if isinstance(index, str) else content_list[index]\n",
    "    id_list = []\n",
    "    for word in content[:sequence_length]:\n",
    "        if word in word2id_dict:\n",
    "            id_ = word2id_dict[word]\n",
    "            id_list.append(id_)\n",
    "        else:\n",
    "            id_list.append(0)\n",
    "    return id_list\n",
    "\n",
    "# 多文章转id列表\n",
    "def get_X(indexes):\n",
    "    idList_list = [get_id_list(i) for i in indexes]\n",
    "    X = kr.preprocessing.sequence.pad_sequences(idList_list, sequence_length)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出Y标签One-Hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(label_list)\n",
    "# 获取标签类别数量\n",
    "category_quantity = labelEncoder.classes_.shape[0]\n",
    "\n",
    "# One-Hot\n",
    "def get_Y(indexes):\n",
    "    # 先转2d供LabelEncoder使用\n",
    "    part_label_list = [label_list[i] for i in indexes]\n",
    "    oneHot_2d_array = labelEncoder.transform(part_label_list)\n",
    "    Y = kr.utils.to_categorical(oneHot_2d_array, category_quantity)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对不同标签类别分权重\n",
    "让每个标签总体上的抽取概率相同，实际操作上等效于让样本不多的标签单样本权重拉高，样本多的标签单样本权重拉低，使其分类能被充分训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_list(label_list):\n",
    "    count_series = pd.value_counts(label_list)\n",
    "    category_quantity = len(count_series)\n",
    "    category_weights = 1 / category_quantity\n",
    "    # 利用count_series分权重\n",
    "    label2weights_dict = dict([(a, b) for a, b in zip(count_series.index, category_weights / count_series)])\n",
    "    probability_list = [label2weights_dict[i] for i in label_list]\n",
    "    return probability_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量数据生成器线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sample_quantity = len(label_list)\n",
    "index_1d_array = np.arange(sample_quantity)\n",
    "train_index_1d_array, test_index_1d_array = train_test_split(index_1d_array, random_state=2019)\n",
    "train_label_list = [label_list[k] for k in train_index_1d_array]\n",
    "train_probability_list = get_probability_list(train_label_list)\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "class BatchDataThread(threading.Thread):\n",
    "    def __init__(self, queue):\n",
    "        super(BatchDataThread, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.start()\n",
    "    \n",
    "    def run(self):\n",
    "        while not self._is_stopped:\n",
    "            if self.queue.qsize() < 4:\n",
    "                selected_indexes = np.random.choice(\n",
    "                    train_index_1d_array, size=batch_size, p=train_probability_list)\n",
    "                batch_X = get_X(selected_indexes)\n",
    "                batch_Y = get_Y(selected_indexes)\n",
    "                put_tuple = batch_X.astype('int32'), batch_Y.astype('float32')\n",
    "                self.queue.put(put_tuple)\n",
    "            time.sleep(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量数据生成器类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "class BatchDataGenerator(object):\n",
    "    def __init__(self, worker_quantity=4):\n",
    "        self.queue = queue.Queue()\n",
    "        for i in range(worker_quantity):\n",
    "            BatchDataThread(self.queue)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch_data = self.queue.get()\n",
    "        return batch_data\n",
    "    \n",
    "    \n",
    "batchData_generator = BatchDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-011ea027cf5d>:12: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /Users/fellno/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-10-011ea027cf5d>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sequence_length = 600\n",
    "X_holder = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y_holder = tf.placeholder(tf.float32, [None, category_quantity])\n",
    "data_0 = X_holder # N *  600\n",
    "vocabulary_size = 7000\n",
    "embedding_size = 100\n",
    "layer_1 = tf.get_variable('embedding', [vocabulary_size, embedding_size])\n",
    "data_1 = tf.nn.embedding_lookup(layer_1, data_0) # N * 600 * 100\n",
    "filter_quantiy = 128 \n",
    "layer_2 = tf.layers.conv1d # 3 * 100 * 128\n",
    "data_2 = layer_2(data_1, filter_quantiy, 3, padding='SAME') # N * 600 * 128\n",
    "layer_3 = tf.layers.conv1d # 5 * 100 * 128\n",
    "data_3 = layer_3(data_1, filter_quantiy, 5, padding='SAME') # N * 600 * 128\n",
    "layer_4 = tf.layers.conv1d # 7 * 100 * 128\n",
    "data_4 = layer_4(data_1, filter_quantiy, 7, padding='SAME') # N * 600 * 128\n",
    "layer_5 = tf.concat\n",
    "data_5 = layer_5([data_2, data_3, data_4], axis=2) # N * 600 * 384\n",
    "layer_6 = tf.reduce_max\n",
    "data_6 = layer_6(data_5, [1]) # N * 384\n",
    "layer_7 = tf.layers.dense # 384 * 128\n",
    "fc1_units = 128\n",
    "data_7 = layer_7(data_6, fc1_units) # N * 128\n",
    "layer_8 = tf.nn.relu\n",
    "data_8 = layer_8(data_7) # N * 128\n",
    "layer_9 = tf.layers.dense\n",
    "data_9 = layer_9(data_8, category_quantity) # N * 14\n",
    "layer_10 = tf.nn.softmax\n",
    "data_10 = layer_10(data_9) # N * 14\n",
    "layer_11 = tf.nn.softmax_cross_entropy_with_logits_v2\n",
    "data_11 = layer_11(labels=Y_holder, logits=data_9) # N\n",
    "loss = tf.reduce_mean(data_11) # 1\n",
    "learning_rate = 5e-4\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "isCorrect = tf.equal(tf.argmax(Y_holder, 1), tf.argmax(data_10, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session = get_session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:5000 Loss:0.1789 Acc:0.9609 Train Speed:0.55 steps/sec\r"
     ]
    }
   ],
   "source": [
    "train_steps = 5000\n",
    "startTime = time.time()\n",
    "for step in range(1, train_steps+1):\n",
    "    batch_X, batch_Y = next(batchData_generator)\n",
    "    session.run(train, {X_holder:batch_X, Y_holder:batch_Y})\n",
    "    if step % 2 == 0 :\n",
    "        loss_value, accuracy_value = session.run([loss, accuracy], {X_holder:batch_X, Y_holder:batch_Y})\n",
    "        usedTime = time.time() - startTime\n",
    "        speed = step / usedTime\n",
    "        print_string = 'Step:{0} Loss:{1:.4f} Acc:{2:.4f} Train Speed:{3:.2f} steps/sec'.format(step, loss_value, accuracy_value, speed)\n",
    "        print_flush(print_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected text content: 张曼玉向汶川地震灾区捐款200万元，是个人捐款最多的女明星 \n",
      "True label: 娱乐\n",
      "Predict label: 世界\n",
      "Predict latent label: 娱乐\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def predict(input_content):\n",
    "    id_list = get_id_list(input_content)\n",
    "    #  切割输入\n",
    "    X = kr.preprocessing.sequence.pad_sequences([id_list], sequence_length)\n",
    "    # 输入X数据，求图的data_10，即SoftMax层获得各分类概率矩阵Y\n",
    "    Y = session.run(data_10, {X_holder:X})\n",
    "    # 取概率矩阵中最大元素的索引为结果\n",
    "    y = np.argmax(Y, axis = 1)\n",
    "    # 第二大权重\n",
    "    y_latent = np.argsort(np.max(Y, axis=0))[-2]\n",
    "    # 解析结果\n",
    "    label, label_latent = labelEncoder.inverse_transform(y)[0], labelEncoder.inverse_transform([y_latent])[0]\n",
    "    return label, label_latent\n",
    "\n",
    "selected_index = np.random.choice(test_index_1d_array, 1)[0]\n",
    "selected_content = content_list[selected_index]\n",
    "true_label = label_list[selected_index]\n",
    "predict_label = predict(selected_content)\n",
    "\n",
    "print(\"Selected text content: \" + selected_content)\n",
    "print(\"True label: \" + true_label)\n",
    "print(\"Predict label: \" + predict_label[0])\n",
    "print(\"Predict latent label: \" + predict_label[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209019 / 209019 Cost time: 548.24 seconds.\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>体育</th>\n",
       "      <th>娱乐</th>\n",
       "      <th>家居</th>\n",
       "      <th>彩票</th>\n",
       "      <th>情感</th>\n",
       "      <th>房产</th>\n",
       "      <th>教育</th>\n",
       "      <th>时尚</th>\n",
       "      <th>时政</th>\n",
       "      <th>游戏</th>\n",
       "      <th>社会</th>\n",
       "      <th>科技</th>\n",
       "      <th>股票</th>\n",
       "      <th>财经</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>体育</th>\n",
       "      <td>32790</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>娱乐</th>\n",
       "      <td>142</td>\n",
       "      <td>22169</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>36</td>\n",
       "      <td>188</td>\n",
       "      <td>124</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>家居</th>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>彩票</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>情感</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>房产</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4675</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>教育</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10261</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时尚</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3180</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>时政</th>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>268</td>\n",
       "      <td>22</td>\n",
       "      <td>14537</td>\n",
       "      <td>11</td>\n",
       "      <td>261</td>\n",
       "      <td>175</td>\n",
       "      <td>135</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>游戏</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5836</td>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>社会</th>\n",
       "      <td>42</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>421</td>\n",
       "      <td>12</td>\n",
       "      <td>273</td>\n",
       "      <td>15</td>\n",
       "      <td>11298</td>\n",
       "      <td>262</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>科技</th>\n",
       "      <td>47</td>\n",
       "      <td>167</td>\n",
       "      <td>245</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>262</td>\n",
       "      <td>32</td>\n",
       "      <td>341</td>\n",
       "      <td>523</td>\n",
       "      <td>442</td>\n",
       "      <td>37815</td>\n",
       "      <td>450</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>股票</th>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>376</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>448</td>\n",
       "      <td>36280</td>\n",
       "      <td>1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>财经</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>344</td>\n",
       "      <td>8535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       体育     娱乐    家居    彩票   情感    房产     教育    时尚     时政    游戏     社会  \\\n",
       "体育  32790    111    20    76    2     2     43    13     40     4     40   \n",
       "娱乐    142  22169   123     2    9    16    127   117     71    36    188   \n",
       "家居     11     34  7860     0    5    24     26    23      4     5     26   \n",
       "彩票     20      4     2  1852    0     0      0     0      2     0     12   \n",
       "情感      1      0     2     1  898     0      3     2      0     0      0   \n",
       "房产      4     10    76     1    2  4675     16     4     16     2     53   \n",
       "教育     10     23    23     2    2     4  10261    10     55     7     84   \n",
       "时尚      2     15    43     0    0     0     13  3180      2     4      4   \n",
       "时政     56     53    36     6    0    34    268    22  14537    11    261   \n",
       "游戏      9     17    11     0    0     1     13     8      5  5836     10   \n",
       "社会     42    111    48    59    2    41    421    12    273    15  11298   \n",
       "科技     47    167   245    10    2    25    262    32    341   523    442   \n",
       "股票     14     26    72     5    0   118     48     9    376    17     16   \n",
       "财经      2     12    28     6    1    49     29     3     46     1     48   \n",
       "\n",
       "       科技     股票    财经  \n",
       "体育     22     13     3  \n",
       "娱乐    124     17    22  \n",
       "家居     59     23    10  \n",
       "彩票      1      0     1  \n",
       "情感      0      0     0  \n",
       "房产     22     70    48  \n",
       "教育     38      9    11  \n",
       "时尚     16      1     2  \n",
       "时政    175    135    69  \n",
       "游戏    196      5     2  \n",
       "社会    262     10    95  \n",
       "科技  37815    450   171  \n",
       "股票    448  36280  1365  \n",
       "财经     51    344  8535  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predict_test():\n",
    "    startTime = time.time()\n",
    "    test_sample_quantity = len(test_index_1d_array)\n",
    "    batch_size = 100\n",
    "    predict_Y_list = []\n",
    "    \n",
    "    for i in range(0, test_sample_quantity, batch_size):\n",
    "        part_index_1d_array = test_index_1d_array[i: i + batch_size]\n",
    "        batch_X = get_X(part_index_1d_array)\n",
    "        predict_Y = session.run(data_10, {X_holder:batch_X})\n",
    "        predict_Y_list.extend(predict_Y)\n",
    "        usedTime = time.time() - startTime\n",
    "        print_string = \"{0} / {1} Cost time: {2:.2f} seconds.\".format(i, test_sample_quantity, usedTime)\n",
    "        print_flush(print_string)\n",
    "    \n",
    "    print_string = \"{0} / {1} Cost time: {2:.2f} seconds.\".format(test_sample_quantity, test_sample_quantity, usedTime)\n",
    "    print_flush(print_string)\n",
    "    \n",
    "    Y = np.array(predict_Y_list)\n",
    "    y = np.argmax(Y, axis=1)\n",
    "    predict_label_list = labelEncoder.inverse_transform(y)\n",
    "    \n",
    "    return predict_label_list\n",
    "\n",
    "test_label_list = [label_list[i] for i in test_index_1d_array]\n",
    "predict_label_list = predict_test()\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(test_label_list, predict_label_list),\n",
    "             columns = labelEncoder.classes_, index = labelEncoder.classes_)\n",
    "\n",
    "if not os.path.isdir(\"./results/\" + name_of_predictor):\n",
    "    os.makedirs(\"./results/\" + name_of_predictor)\n",
    "cm.to_csv(\"./results/\" + name_of_predictor + '/' + name_of_predictor + '_CNNTensor_CM.csv')\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 报告表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>0.989140</td>\n",
       "      <td>0.988276</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>33179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>娱乐</td>\n",
       "      <td>0.974376</td>\n",
       "      <td>0.957087</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>23163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>家居</td>\n",
       "      <td>0.915124</td>\n",
       "      <td>0.969174</td>\n",
       "      <td>0.941374</td>\n",
       "      <td>8110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>彩票</td>\n",
       "      <td>0.916832</td>\n",
       "      <td>0.977825</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>情感</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>0.990077</td>\n",
       "      <td>0.981421</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>房产</td>\n",
       "      <td>0.937062</td>\n",
       "      <td>0.935187</td>\n",
       "      <td>0.936123</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>教育</td>\n",
       "      <td>0.889939</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.929902</td>\n",
       "      <td>10539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>时尚</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.968921</td>\n",
       "      <td>0.946851</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>时政</td>\n",
       "      <td>0.921930</td>\n",
       "      <td>0.928111</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>15663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>游戏</td>\n",
       "      <td>0.903266</td>\n",
       "      <td>0.954687</td>\n",
       "      <td>0.928265</td>\n",
       "      <td>6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>社会</td>\n",
       "      <td>0.905143</td>\n",
       "      <td>0.890377</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>12689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>科技</td>\n",
       "      <td>0.963955</td>\n",
       "      <td>0.932967</td>\n",
       "      <td>0.948208</td>\n",
       "      <td>40532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>股票</td>\n",
       "      <td>0.971170</td>\n",
       "      <td>0.935196</td>\n",
       "      <td>0.952844</td>\n",
       "      <td>38794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>财经</td>\n",
       "      <td>0.825914</td>\n",
       "      <td>0.932277</td>\n",
       "      <td>0.875879</td>\n",
       "      <td>9155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>总体</td>\n",
       "      <td>0.948649</td>\n",
       "      <td>0.947215</td>\n",
       "      <td>0.947503</td>\n",
       "      <td>209019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label  Precision    Recall        F1  Support\n",
       "0      体育   0.989140  0.988276  0.988708    33179\n",
       "1      娱乐   0.974376  0.957087  0.965654    23163\n",
       "2      家居   0.915124  0.969174  0.941374     8110\n",
       "3      彩票   0.916832  0.977825  0.946346     1894\n",
       "4      情感   0.972914  0.990077  0.981421      907\n",
       "5      房产   0.937062  0.935187  0.936123     4999\n",
       "6      教育   0.889939  0.973622  0.929902    10539\n",
       "7      时尚   0.925764  0.968921  0.946851     3282\n",
       "8      时政   0.921930  0.928111  0.925010    15663\n",
       "9      游戏   0.903266  0.954687  0.928265     6113\n",
       "10     社会   0.905143  0.890377  0.897700    12689\n",
       "11     科技   0.963955  0.932967  0.948208    40532\n",
       "12     股票   0.971170  0.935196  0.952844    38794\n",
       "13     财经   0.825914  0.932277  0.875879     9155\n",
       "999    总体   0.948649  0.947215  0.947503   209019"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def eval_model(y_true, y_pred, labels):\n",
    "    # 计算每个分类的Precision, Recall, f1, support\n",
    "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    # 计算总体的平均Precision, Recall, f1, support\n",
    "    tot_p = np.average(p, weights=s)\n",
    "    tot_r = np.average(r, weights=s)\n",
    "    tot_f1 = np.average(f1, weights=s)\n",
    "    tot_s = np.sum(s)\n",
    "    res1 = pd.DataFrame({\n",
    "        u'Label': labels,\n",
    "        u'Precision': p,\n",
    "        u'Recall': r,\n",
    "        u'F1': f1,\n",
    "        u'Support': s\n",
    "    })\n",
    "    res2 = pd.DataFrame({\n",
    "        u'Label': ['总体'],\n",
    "        u'Precision': [tot_p],\n",
    "        u'Recall': [tot_r],\n",
    "        u'F1': [tot_f1],\n",
    "        u'Support': [tot_s]\n",
    "    })\n",
    "    res2.index = [999]\n",
    "    res = pd.concat([res1, res2])\n",
    "    res.to_csv(\"./results/\" + name_of_predictor + '/' + name_of_predictor + '_CNNTensor_PRFS.csv')\n",
    "    return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]\n",
    "\n",
    "eval_model(test_label_list, predict_label_list, labelEncoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 复用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要随便乱点！！！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./TouTiao/trained_model/CNN_Tensorflow.ckpt'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "modelFilePath = \"./\" + name_of_predictor + \"/trained_model/CNN_Tensorflow.ckpt\"\n",
    "saver.save(session, modelFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./TouTiao/trained_model/CNN_Tensorflow.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "session = get_session()\n",
    "modelFilePath = \"./\" + name_of_predictor + \"/trained_model/CNN_Tensorflow.ckpt\"\n",
    "saver.restore(session, modelFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 即时输入预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 娱乐\n",
      "Latent predict: 文化\n"
     ]
    }
   ],
   "source": [
    "input_content = \"\"\"\n",
    "这轮改变，是从它关停周播剧场“青春进行时”开始的。\n",
    "许多观众没有注意到的是，这个历时2015年到2021年六年时间\n",
    "曾播出过《旋风少女》、《漂亮的李慧珍》、《流星花园》、《楚乔传》、《择天记》等爆款青春偶像剧的电视剧播放剧场，已经从湖南卫视悄然消失。\n",
    "\"\"\"\n",
    "\n",
    "print(\"Predict: \" + predict(input_content)[0])\n",
    "print(\"Latent predict: \" + predict(input_content)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新浪热搜即时预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>热搜标题</th>\n",
       "      <th>预测结果</th>\n",
       "      <th>备用结果</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新垣结衣星野源结婚</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>互联网人一分钟之内痛失两个老婆</td>\n",
       "      <td>科技</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>中国疫苗接种剂次全球第一</td>\n",
       "      <td>农业</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>石原里美或将退圈从政</td>\n",
       "      <td>旅游</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>关晓彤 植物肉</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>农业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>三句话让男人为我花18万</td>\n",
       "      <td>民生</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>印度一男子在树上隔离11天</td>\n",
       "      <td>世界</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>兵马俑也忍不住出雪糕了</td>\n",
       "      <td>旅游</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>工信部点名要求下架APP仍可下载</td>\n",
       "      <td>科技</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>南昌杀妻抛尸案将择期宣判</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>陈建斌带着两个行李箱向蒋勤勤求婚</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>哇唧唧哇是龙丹妮的网名</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>星野源发文</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>没点文化都不敢结婚了</td>\n",
       "      <td>文化</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>六安新增1例无症状感染者</td>\n",
       "      <td>房产</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>黄晓明 否认离婚</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>微信拍一拍新增炸一炸功能</td>\n",
       "      <td>科技</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>郑秀晶漫画腿</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HM未标明产品成分被责令改正</td>\n",
       "      <td>金融</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>华为发布会</td>\n",
       "      <td>科技</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>迪丽热巴和鸽子合照</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>林峯在厕所求婚张馨月</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>赵丽颖带保温杯深夜酒吧会友</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>清华附中辟谣双国籍可直通清华</td>\n",
       "      <td>教育</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>特朗普集团遭刑事调查</td>\n",
       "      <td>世界</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>刘涛秦海璐姐妹情</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>privilege水果的正确吃法</td>\n",
       "      <td>科技</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>在同一个老师身上社死两次</td>\n",
       "      <td>民生</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>张杰肌肉照</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>冷战多少天不联系算分手</td>\n",
       "      <td>游戏</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>秦海璐王新军取消婚礼的原因</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>军事</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>男子疑因色弱不能考驾照被分手</td>\n",
       "      <td>教育</td>\n",
       "      <td>汽车</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>用了面膜特效的大爷</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>小女孩手术台上给自己讲故事</td>\n",
       "      <td>体育</td>\n",
       "      <td>教育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>我国成功发射海洋二号D星</td>\n",
       "      <td>军事</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>景区雪糕大战是文创界内卷吗</td>\n",
       "      <td>旅游</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>上班后离家近有多重要</td>\n",
       "      <td>教育</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>顾川姜小宁分手</td>\n",
       "      <td>体育</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>民政部回应520不办离婚</td>\n",
       "      <td>军事</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>奥巴马谈UFO和外星人</td>\n",
       "      <td>体育</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>养猪场招人研究生年薪18万起</td>\n",
       "      <td>农业</td>\n",
       "      <td>教育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>深圳赛格大厦再次出现晃动</td>\n",
       "      <td>体育</td>\n",
       "      <td>游戏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>怦然心动20岁</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>情侣吵架女子开车顶翻男友</td>\n",
       "      <td>汽车</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>监控中外公亲吻外婆遗像</td>\n",
       "      <td>娱乐</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>暗物质卫星悟空发布第三批科学成果</td>\n",
       "      <td>游戏</td>\n",
       "      <td>文化</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>巴勒斯坦男子哭着安慰唯一幸存的儿子</td>\n",
       "      <td>世界</td>\n",
       "      <td>娱乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>警方通报内蒙古文旅厅副厅长自杀</td>\n",
       "      <td>旅游</td>\n",
       "      <td>世界</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>郎平惠若琪进入国际排联</td>\n",
       "      <td>体育</td>\n",
       "      <td>金融</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>男孩子在外也要保护好自己</td>\n",
       "      <td>教育</td>\n",
       "      <td>旅游</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 热搜标题 预测结果 备用结果\n",
       "1           新垣结衣星野源结婚   娱乐   军事\n",
       "2     互联网人一分钟之内痛失两个老婆   科技   娱乐\n",
       "3        中国疫苗接种剂次全球第一   农业   金融\n",
       "4          石原里美或将退圈从政   旅游   文化\n",
       "5             关晓彤 植物肉   娱乐   农业\n",
       "6        三句话让男人为我花18万   民生   娱乐\n",
       "7       印度一男子在树上隔离11天   世界   旅游\n",
       "8         兵马俑也忍不住出雪糕了   旅游   军事\n",
       "9    工信部点名要求下架APP仍可下载   科技   金融\n",
       "10       南昌杀妻抛尸案将择期宣判   娱乐   世界\n",
       "11   陈建斌带着两个行李箱向蒋勤勤求婚   娱乐   金融\n",
       "12        哇唧唧哇是龙丹妮的网名   娱乐   体育\n",
       "13              星野源发文   娱乐   游戏\n",
       "14         没点文化都不敢结婚了   文化   娱乐\n",
       "15       六安新增1例无症状感染者   房产   金融\n",
       "16           黄晓明 否认离婚   娱乐   世界\n",
       "17       微信拍一拍新增炸一炸功能   科技   金融\n",
       "18             郑秀晶漫画腿   娱乐   文化\n",
       "19     HM未标明产品成分被责令改正   金融   科技\n",
       "20              华为发布会   科技   军事\n",
       "21          迪丽热巴和鸽子合照   娱乐   旅游\n",
       "22         林峯在厕所求婚张馨月   娱乐   旅游\n",
       "23      赵丽颖带保温杯深夜酒吧会友   娱乐   体育\n",
       "24     清华附中辟谣双国籍可直通清华   教育   文化\n",
       "25         特朗普集团遭刑事调查   世界   金融\n",
       "26           刘涛秦海璐姐妹情   娱乐   体育\n",
       "27   privilege水果的正确吃法   科技   游戏\n",
       "28       在同一个老师身上社死两次   民生   文化\n",
       "29              张杰肌肉照   娱乐   体育\n",
       "30        冷战多少天不联系算分手   游戏   军事\n",
       "31      秦海璐王新军取消婚礼的原因   娱乐   军事\n",
       "32     男子疑因色弱不能考驾照被分手   教育   汽车\n",
       "33          用了面膜特效的大爷   娱乐   金融\n",
       "34      小女孩手术台上给自己讲故事   体育   教育\n",
       "35       我国成功发射海洋二号D星   军事   科技\n",
       "36      景区雪糕大战是文创界内卷吗   旅游   世界\n",
       "37         上班后离家近有多重要   教育   世界\n",
       "38            顾川姜小宁分手   体育   娱乐\n",
       "39       民政部回应520不办离婚   军事   世界\n",
       "40        奥巴马谈UFO和外星人   体育   游戏\n",
       "41     养猪场招人研究生年薪18万起   农业   教育\n",
       "42       深圳赛格大厦再次出现晃动   体育   游戏\n",
       "43            怦然心动20岁   娱乐   旅游\n",
       "44       情侣吵架女子开车顶翻男友   汽车   娱乐\n",
       "45        监控中外公亲吻外婆遗像   娱乐   世界\n",
       "46   暗物质卫星悟空发布第三批科学成果   游戏   文化\n",
       "47  巴勒斯坦男子哭着安慰唯一幸存的儿子   世界   娱乐\n",
       "48    警方通报内蒙古文旅厅副厅长自杀   旅游   世界\n",
       "49        郎平惠若琪进入国际排联   体育   金融\n",
       "50       男孩子在外也要保护好自己   教育   旅游"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_0) '\n",
    "                         'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                         'Chrome/86.0.4240.198 Safari/537.36'}\n",
    "html = requests.get('https://s.weibo.com/top/summary?cate=realtimehot', headers=headers)\n",
    "page = html.content.decode()\n",
    "\n",
    "res = re.findall(\n",
    "    r'<tr class=\"\">\\s*<td class=\"td-01 ranktop\">(\\d+)<\\/td>\\s*<td class=\"td-02\">\\s*<a href=\"\\/('\n",
    "    r'.*?)&.*?target=\"_blank\">(.*?)<\\/a>', page, re.S)\n",
    "\n",
    "# ind = [i[0] for i in res]\n",
    "# link = ['https://s.weibo.com/' + i[1] for i in res]\n",
    "title = [i[2] for i in res]\n",
    "pred = [predict(t)[0] for t in title]\n",
    "pred_latent = [predict(t)[1] for t in title]\n",
    "\n",
    "\n",
    "dataFrame = pd.DataFrame({\n",
    "        u'热搜标题': title,\n",
    "        u'预测结果': pred,\n",
    "        u'备用结果': pred_latent\n",
    "    })\n",
    "dataFrame.index = [i + 1 for i in range(50)]\n",
    "\n",
    "dataFrame[['热搜标题', '预测结果', '备用结果']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 501,
   "position": {
    "height": "523px",
    "left": "1419px",
    "right": "20px",
    "top": "84px",
    "width": "431px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
